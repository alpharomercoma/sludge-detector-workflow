data:
  root_dir: /mnt/disks/hyper_ml_storage/PE-Video_dataset
  train_split: train
  val_split: test
  num_frames: 4
  id_field: video_id
  caption_field: human_caption

model:
  clip_model_name: openai/clip-vit-large-patch14
  num_query_tokens: 16
  qformer_num_layers: 2
  qformer_num_heads: 4
  qformer_mlp_dim: 1024
  dropout: 0.1
  llm_model_name: lmsys/vicuna-7b-v1.3

train:
  max_caption_len: 200
  batch_size: 4
  num_workers: 4
  learning_rate: 5e-5
  weight_decay: 0.01
  num_epochs: 1
  eval_steps: 500
  save_steps: 1000
  grad_accum_steps: 1
  output_dir: /mnt/disks/hyper_ml_storage/PE-Video_dataset/checkpoints
  early_stopping_patience: 3
  eval_subset_size: 50

cache:
  hf_cache_dir: /mnt/disks/hyper_ml_storage/PE-Video_dataset/hf_cache

resources:
  cpu_threads: 2
  gpu_mem_fraction: 0.8
